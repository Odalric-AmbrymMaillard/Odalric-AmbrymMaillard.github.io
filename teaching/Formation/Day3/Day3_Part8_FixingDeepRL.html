<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>INRIA Academy</title>
	<script src="mathjax-shortcuts.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>	
    <link rel="stylesheet" href="slides.css">
</head>
<body>
    <div class="slide-container">
<!-- Slide 1: Title Slide -->
<section class="slide intro">
    <h1>Fixing Deep Reinforcement Learning</h1>
	
    <div>
		<p><strong>Odalric-Ambrym Maillard</strong></p>
		<p><strong>HORIBA</strong></p>
		<p><strong>April 22, 2025</strong></p>
	<img src="logos/Inria Academy.png" width="250px">
	</div>
</section>

<section class="slide intro">
    <h1>Roadmap</h1>	
	
	A study of the application article 
	<p class="highlight-box">
	<br><strong>"Information-Based Exploration via Random Features
for Reinforcement Learning"</strong>, <br>
	by Radji, W. and Maillard, O-A.
	</p>
	   <div>
	<ul>
	<li>Optimism in Deep  RL</li>
	<li>Exploration bonus</li>
	<li>Pseudo-count challenge</li>
	<li>An information-gain principle</li>
	<li>Benefits</li>
	</ul>
	</div>
</section>


<section class="slide intro">
    <h1>Optimism in Deep  RL</h1>	
	
	<div>
	<p class="highlight-box">
	Objective<br>
	\(J(\pi) = \Esp_{\pi,{\bf p}}\bigg[\sum\limits_{t=0}^\infty \gamma^t {\bf r}(s_t,a_t)\bigg]\) <br> with unkwnown quantities.
	</p>
	</div>
	<div>
	<p class="highlight-box">Natural idea<br>
	Replace reward with <br>\({\bf r}_{\text{total}}(s,a)= {\bf r}(s,a)+\beta{\bf r}^+(s,a)\)<br> to account for uncertainty.
	</p>
	</div>
	<div>
	<l>How to build \({\bf r}^+\)?</l>
	</div>
</section>


<section class="slide intro">
    <h1>Challenge in large state-action spaces</h1>	
	

	<div>
	<p class="highlight-box">
	In tabular MDPs,<br> \({\bf r}^+(s,a) \approx 1/\sqrt{n_t(s,a)}\),<br> \(n_t(s,a)\): number of visit counts.
	</p>
	</div>
	<div>
	In non-countable spaces, these counts are <l>mostly \(0\)</l>.
	</div>
	<div>
	To apply optimistic principle, we scrutinize <l>confidence intervals</l> for continuous spaces.
	</div>

</section>

<section class="slide intro">
    <h1>The information gain.</h1>	
	<div>
	In regression, <l>information gain</l> controls size of confidence intervals.<br>
	
	<p class="highlight-box">
	\( \Pr\bigg( \KL(\hat \theta_n, \theta) \geq \frac{\log(1/\delta)+IG_n(\theta)}{n}\bigg)\leq \delta \)
	</p>
	where \(IG_n(\theta)\) is information gain with all data received up to time \(n\).
</div>
<div>
In Kernel regresssion, assuming a Gaussian process \(f\sim GP(0,k(\cdot,\cdot))\) with observation noise \(\eta\sim\cN(0,\sigma^2)\),<br>
the  <l>instantaneous information gain </l> between
\(\cD_n= \{(x_i,y_i)\}_{i=1}^n\) and \(\cD_{n+1}=\cD_n\cup\{(x_\star,y_\star)\) is

	<p class="highlight-box">
\(
IG_n(x_\star,y_\star) = \frac{1}{2}\log\bigg(\frac{ \det(K_{n+1}+\sigma^2I_{n+1})}{\det(K_{n}+\sigma^2I_{n})}\bigg)\)
</p>
where \(K_n = [k(x_i,x_j)]_{i,j}\) is an \(n\times n\) matrix.
</div>

</section>

<section class="slide intro">
    <h1>Choice of bonus: information gain.</h1>	
<div>
For a kernel \(k(x,x')\simeq \phi(x)^\top\phi(x)\) with \(\phi:\cX\to\Real^d\),<br> the instantaneous information can be <l>approximated</l> with

	<p class="highlight-box">
\({\bf r}^+(x_\star)=\frac{1}{2}\log\bigg(1 + \phi(x_\star)^\top\Big(\Phi_n^\top \Phi_n +\lambda I_d)^{-1}\phi(x_\star)\bigg)\)
</p>
</div>
<div>
 <l>Random Feature maps</l> enable to obtain such an approximation of a kernel <br>(random projection method) with controlled error.
</div>
</section>
	

<section class="slide intro">
    <h1>Promising results</h1>	

<div>

	<img src="fig3/RFIG_fig.png" width="1600px">
</div>

<div>

	<img src="fig3/RFIG_table.png" width="1200px">
</div>

</section>
<!--
<section class="slide intro">  <h1>Complementary reading</h1>	

<div>
	MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization : https://arxiv.org/abs/2412.12098 

</div>
</section>
-->
<section class="slide conclusion">
    <h2>Thank you</h2>
	
	
	<a href="Day3_Part1_PlanJourneeTeaser.html">Back</a>
</section>
    </div>
    
    <div class="controls">
        <button class="btn" id="prev">⬅ Previous</button>
        <button class="btn" id="next">Next ➡</button>
    </div>
    
    <script src="slides.js"></script>
</body>
</html>