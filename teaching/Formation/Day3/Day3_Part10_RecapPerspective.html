<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>INRIA Academy</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>	
    <link rel="stylesheet" href="slides.css">
</head>
<body>
    <div class="slide-container">
<!-- Slide 1: Title Slide -->
<section class="slide intro">
    <h1>RECAP & PERSPECTIVE</h1>
	
    <div>
		<p><strong>Odalric-Ambrym Maillard</strong></p>
		<p><strong>HORIBA</strong></p>
		<p><strong>July 09, 2025</strong></p>
	<img src="logos/Inria Academy.png" width="250px">
	</div>
</section>

<section class="slide intro">
    <h1>Road map</h1>	
	   <div>
	<ul>
	<li> What we have seen </li>
	<li> Take home messages </li>
	</ul>
	</div>	
</section>





<section class="slide intro">
    <h1>What we have seen</h1>	
	   <div>
	   <ul>
	<li>From tabular to parametric representations</li>
	<li>Linear and non linear representations</li>
	<li>Critic strategies, Actor strategies.</li>
	<li>Challenges of approximation</li>
	<li>Policy gradient theorem</li>
	<li>DQN, PPO, etc</li>
	<li>Caveats of Deep learning</li>
	<li>Exploration bonus</li>
	</ul>
	</div>	
</section>



<section class="slide intro">
    <h1>Take home messages ?</h1>	

</section>

<section class="slide technical">
    <h1>Bandit-inspired strategies for Large dynamical systems?</h1>	
<div>

	<p class="highlight-box">
MED-LQ: Minimum empirical divergence for linear quadratic systems.
</p>
<p>
We apply a bandit principle "confusing instance search" to linear quadratic systems.
</p>
</div>
	<div>

	<img src="fig3/MEDLQ.png" width="1200px">
</div>
</section>



<section class="slide technical">
    <h1>Novel trends</h1>
	
	<div>
	<ul>
	<li>	<a href="https://arxiv.org/abs/2503.09817">Temporal Difference Flows</a></li> <br>
	<li>
	<a href="https://arxiv.org/abs/2206.07568">
	Contrastive Learning as Goal-Conditioned Reinforcement Learning</a></li>
 <br>
	
	<li>
	<a href="https://arxiv.org/abs/2408.05804">
	A Single Goal is All You Need: Skills and Exploration Emerge from Contrastive RL without Rewards, Demonstrations, or Subgoals</a></li>
	<br>


<li>
	<a href="https://arxiv.org/abs/2406.12589 ">Discovering Minimal Reinforcement Learning Environments</a></li>
	</ul>

	</div>	
</section>

<section class="slide conclusion">
    <h2>Thank you</h2>
	<a href="Day3_Part1_PlanJourneeTeaser.html">Back</a>
</section>
    </div>
	
	
    <div class="controls">
        <button class="btn" id="prev">⬅ Previous</button>
        <button class="btn" id="next">Next ➡</button>
    </div>
    
    <script src="slides.js"></script>
</body>
</html>