<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Internship Proposal</title>
    <!-- MathJax for LaTeX rendering -->
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js">
    </script>
	
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- CSS Styling -->
    <style>
        body {
            font-family: 'Georgia', serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f8f9fa;
            color: #333;
        }
        .header {
            text-align: center;
            margin: 20px 0;
        }
		
		.header p {
		text-align: center; /* Override the global p style */
		}
        .logos {
            display: flex;
            justify-content: space-evenly;
            margin: 10px auto;
            align-items: center;
            flex-wrap: wrap;
        }
        .logos img {
            max-height: 60px;
            margin: 10px;
        }
        .title {
            text-align: center;
            font-size: 1.8em;
            font-weight: bold;
            margin: 20px 0;
        }
        hr {
            border: none;
            height: 2px;
            background-color: #333;
            margin: 20px 0;
        }
        .section {
            margin: 20px auto;
            max-width: 800px;
            padding: 10px;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
        }
        h3 {
            font-size: 1.3em;
            margin-bottom: 10px;
        }
        p {
            margin: 10px 0;
            text-align: justify;
        }
        .keywords {
            font-weight: bold;
            color: #0056b3;
        }
        .footer {
            text-align: center;
            font-size: 0.9em;
            margin: 40px 0;
            color: #555;
        }
		.footer p {
		text-align: center; /* Override the global p style */
		}
        .bibliography {
			margin: 20px auto;
            max-width: 800px;
            padding: 10px;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 8px;			
        }
		
		.bibliography p {
		text-align: justify; /* Override the global p style */
		}
		
		
.bibliography h3 {
    font-size: 1.5em;
    margin-bottom: 15px;
    color: #333;
}

.bibliography ul {
    list-style-type: none;
    padding-left: 0;
}

.bibliography li {
    margin-bottom: 10px;
    font-size: 1em;
    line-height: 1.5em;
	text-align: justify;
}

.bibliography li i {
    font-style: italic;
    color: #555;
}

.citation {
    background-color: #d1c4e9;
    color: #4a148c;
    padding: 2px 6px;
    border-radius: 3px;
    font-weight: bold;
    font-size: 0.9em;
}

/* Bibliography Citation Tags */
.citation-tag {
    background-color: #d1c4e9;
    color: #4a148c;
    padding: 2px 6px;
    border-radius: 3px;
    font-weight: bold;
    font-size: 0.95em;
}

    </style>
</head>
<body>
    <!-- Logos Header -->
    <div class="logos">
        <img src="logo_INRIA.png" alt="INRIA Logo">
        <img src="logoCRIStAL.png" alt="CRIStAL Logo">
        <img src="Logo_Universite_Lille.png" alt="Université de Lille Logo">
        <img src="logo_CNRS.png" alt="CNRS Logo">
    </div>

    <!-- Title -->
    <div class="header">
        <h1>Research Topic Proposal</h1>
        <p><strong>Centre Inria de l'Université de Lille</strong><br>
        Team project Scool -- Spring 2025</p>
        <div class="title">
            <em>“Piecewise-deterministic Hawkes-Markov Decision Processes”</em>
        </div>
    </div>

    <!-- Main Content -->
    <div class="section">
        <p><span class="keywords">Keywords:</span> Autonomous Systems, Markov Decision Process, Hawkes process.</p>
        <p><span class="keywords">Investigator:</span> The project is proposed and advised by Odalric-Ambrym Maillard from Inria team-project Scool.</p>
        <p><span class="keywords">Place:</span> This project will be primarily held at the research center Inria Lille -- Nord Europe, 40 avenue Halley, 59650 Villeneuve d'Ascq, France.</p>
    </div>

    <hr>

    <!-- Context Section -->
    <div class="section">
        <h3>Context</h3>
        <p>In this proposal we study  a variant of the traditional Markov Decision Process (MDP) formulation adapted to capture systems displaying an autonomous (that is, uncontrolled) dynamics. Such systems naturally appear when monitoring a physical system. 
For instance, think of a production line which usually works in a nominal way, but as the physical systems ages, some parts spontaneously deteriorate with time or even break, causing the  dynamics of the system to change (autonomously). 
Another example is that of patient followed after an important treatment or medical intervention, 
whose health status evolves autonomously, usually in a positive way, but with potential relapses occurring spontaneously.
Yet another example is the monitoring of an agrosytem, where plants autonomously grow from one stage to the other in a predictable manner, depending on the given conditions and resources available, and this evolution can be modified by sudden changes of weather conditions, or apparition of some pathogen.
In each situation, the decision maker (maintenance officer, physician, farmer) may see a variant of a control problem, with some variables evolving in an autonomous, but predictable way, plus with a specific form on non-stationarity, where the dynamics may suddenly change at seemingly random times. 
The first type of evolution may be modeled e.g. with a popular linear system or PDE formulation, while  the occasional changes modify the parameters of the dynamics. The change occurrences and intensities may further be modeled. 
Elaborating on the considered examples, when a change of dynamics spontaneously occurs, such as a system part that brokes, it is natural to model that some overshoots may appear, that is, a subsequent spontaneous change of the system, caused by the first change.
Such self-excitation is reminiscent of the modeling of earthquakes,  epidemic or biological neurons modeling. 
Now, the agent acts on this system, causing (controlled) impulse jumps of the dynamics. The autonomous evolution suggests that the decision maker should carefully choose not only what intervention to do but also when to perform it. In particular, this means the set of policies considered by a decision maker should handle decision time. </p>
    </div>
 <div class="section">
        <h3>RL models for Spontaneous and Self-exciting Disturbances</h3>
	 <p>Reinforcement learning (RL) has witnessed remarkable success in addressing decision-making problems across discrete and continuous domains. However, many real-world systems remain outside the effective scope of traditional Markov Decision Process (MDP) frameworks, particularly those governed by continuous-time dynamics punctuated by random events. 
My research aims to bridge this gap by extending RL methodologies to autonomous systems described by e.g. <strong>Piecewise Deterministic Markov Processes (PDMPs)</strong> or  <strong>Hawkes processes</strong>. 
These systems naturally emerge in fields as diverse as physics-inspired RL, manufacturing, healthcare and agroecology, where control strategies must account for continuous evolution punctuated by stochastic disturbances.
	 </p>

	 <p>
	 <strong>From Classical Models to Poisson Disturbance</strong>
	 Put simply, unlike classical modeling of bandits considering a treatment produces an immediate output,
one should consider that in healthcare, a patient’s health status evolves continuously (e.g., tumor growth) but is interrupted by stochastic events like relapses or side effects. Similarly, in agroecology, the plant growth dynamics are influenced by random occurrences like pest outbreaks or adverse weather.  Likewise, in manufacturing, a production line operates under predictable dynamics but can experience sudden failures or deterioration over time.
</p>
	 <p>
In hypothesis testing and clinical trials \cite{bartroff2012sequential}, these phenomenon
have been modeled using Poisson processes \cite{li2010conditional}, particularly in vaccine studies considering safety requirement over a large population.
Likewise  in control, PDMPs  where deterministic dynamics govern system evolution between stochastic Poisson events,  offer a more expressive framework compared to 
the traditional MDP by enabling to model spontaneous changes.
These scenarios share a critical feature:  decision-making is influenced by the interplay of deterministic evolution, stochastic events, and require interventions that balance the timing of interventions (e.g., optimal treatment or agricultural practice scheduling) on top of the nature of the intervention (e.g., dosage or method). 
</p>
	 <p>
However, current models typically assume static decision contexts, leaving the integration of such disturbances into dynamic systems and RL frameworks underexplored. Incorporating Poisson disturbances into sequential decision-making hence represents a significant opportunity to extend classical bandit and MDP to alternative models.
By enabling adaptive, resource-efficient decision-making, \hl{PDMPs} provide a rigorous foundation for adapting RL in these domains, enabling policies that address \hl{when} to act and \hl{what} actions to take.
	 </p>

	 <p><strong>From Poisson to Hawkes Processes</strong>
		 Beyond Poisson processes, many systems exhibit self-exciting events, where one occurrence increases the likelihood of subsequent events.  
Hawkes processes are the natural extension, enabling the modeling of cascading failures in factories, relapse dynamics in healthcare (e.g., tumor recurrence), or pest infestations in agroecology. These processes capture the temporal dependencies between events, offering a richer representation of real-world phenomena than memoryless Poisson processes.
Besides, many real-world \hl{interventions} introduce such disturbances that are not instantaneous but unfold over time, resembling aftershocks following an earthquake: administering a medical treatment may cause immediate effects but also trigger side effects at random future times, requiring careful monitoring. 
	Similarly, agroecological practices (e.g., pesticide application) can have delayed effects, such as pest outbreaks influenced by environmental factors, while industrial repairs may induce future system fragility.
	 </p>
 </div>
   <!-- Modeling Section -->
    <div class="section">
        <h3>Modeling</h3>
        <p> Mathematically, the traditional way to model decision in dynamical systems is via the Markov Decision Process framework 
    <span class="citation">Puterman, 2014; Sutton, 2018</span>, which models controlled systems. Autonomous dynamics are 
    naturally specified by flow equations <span class="citation">Davis, 1984; De Saporta et al., 2016; Cleynen et al., 2024</span>, 
    while spontaneous changes are naturally modeled using Hawkes processes 
    <span class="citation">Hawkes, 2018; Siviero et al., 2024</span>.
All three frameworks have been extensively studied in the literature, offering sound basis for possible extensions. We here combine the frameworks of Markov Decision Processes, autonomous dynamics via flow equations, and Hawkes processes to model spontaneous changes. This results in the model:</p>
        <div class="math">$${\bf M} = ((\mathcal{X}, \Theta), \mathcal{A}, (F, \Lambda, Q), c)$$</div>
        <p>Where:</p>
        <ul>
            <li>\(\mathcal{X}\): Position space</li>
            <li>\(\Theta\): Modes parameterizing autonomous dynamics</li>
            <li>\(\mathcal{A}\): Action space for  impulse jumps controlled by the agent</li>
            <li>\(F\): Evolution (flow) between jumps</li>
            <li>\(\Lambda\): Intensity function of the Hawkes process for spontaneous jumps</li>
            <li>\(Q\): Transition kernel specifying the effect of any jump on the mode.</li>
            <li>\(c\): Cost function</li>
        </ul>
    </div>

    <!-- Formalization Section -->

	
    <div class="section">
        <h3>Light formalization</h3>
        <p>The process evolves in a state space \(\mathcal{X} \subseteq \mathbb{R}^d\) with \(d \in \mathbb{N}\), where the position at time \(t \in \mathbb{R}_+\) is denoted \(X_t \in \mathcal{X}\).</p>

        <h4>Autonomous Dynamics</h4>
        <p>Between jump times \(\tau_n, \tau_{n+1}\), the system follows:</p>
        <div class="math">$$\frac{dX_t}{dt} = F(\theta_n, X_t), \quad t \in (\tau_n, \tau_{n+1})$$</div>
        <p>The solution flow \(\Phi_n\) satisfies:</p>
        <div class="math">$$X_t = \Phi_n(X_{\tau_n}, t - \tau_n), \quad t \in (\tau_n, \tau_{n+1})$$</div>

        <h4>Jump Dynamics</h4>
        <p>At jump times \(\tau=\tau_{n+1}\), the system transitions to a new position \(X_\tau\) and mode \(\theta_{n+1}\). Jump types include:</p>
        <ul>
            <li><strong>Natural jumps (\(\natural\)):</strong> Triggered at time \(\tau^{\natural}\) and to position \(X_{\tau^{\natural}}\) by a Hawkes process with intensity function:</li>
        </ul>
        <div class="math">
            $$\lambda(x, t) = \mu(x - X_t) + \sum_{(x_n, t_n) \in \mathcal{H}_t} \phi(x - x_n, t - t_n)$$
        </div>
        <ul>
            <li><strong>Boundary jumps (\(\flat\)):</strong> Triggered at time \(\tau^{\flat}\)  when \(X_t\) reaches the domain boundary \(\partial \mathcal{X}\), to a new position \(X_{\tau^\flat}\sim \beta\) generated from a reset distribution \(\beta\)</li>
            <li><strong>Impulse jumps (\(\sharp\)):</strong> Triggered at time \(\tau^{\sharp}\) controlled by the decision-maker, to either a choosen position \(X_{\tau^\sharp}\) or to \(\Phi_n(X_{\tau_n}, \tau^\sharp - \tau_n)\), choosing action \(a_{n+1} \in \mathcal{A} \)</li>
        </ul>
		<p>Eventually, the next change occurs at \( \tau_{n+1} = \min\{\tau^\natural,\tau^\flat,\tau^\sharp\} \), and the system transits to a new mode according to </p>
		
        <div class="math">
            $$ 	\theta_{n+1}\sim Q(\theta_n,X_{\tau},a_{n+1}), \quad \text{with extended action }\,a_{n+1}\in \mathcal{A}\cup \{\natural,\flat\}$$
        </div>

        <h4>Cost Function</h4>
        <p>The instantaneous cost is defined as \(c(X_t)\) for \(t \notin \{\tau_1,\dots,\tau_n,\dots\}\) and 
		\(c(X_\tau) + c_{a_\tau}\) at a any jump time \(\tau\).</p>
    </div>


<div class="section">
    <h2>Objective and Goals</h2>
    <p>The main objectives of this work are as follows:</p>
    <ul>
	    <li>
		<strong>Hypothesis testing under Hawkes disturbances:</strong>    revisiting the simpler setting of hypothesis testing under Hawkes rather than Poisson disturbances, as considered e.g. in calibration of Vaccine studies.
	    </li>
	    <li>
		    <strong>Multi-armed bandit theory under Poisson and Hawkes disturbances:</strong> Advancing multi-armed bandit theory to handle both Poisson and Hawkes disturbances in an provably optimal way, prior to considering the full-blown dynamical problem.
	    </li>
        <li>
            <strong>Parameter Estimation:</strong> Estimate the parameters of the Hawkes process, including the baseline intensity 
            <i>μ</i> and the kernel <i>ϕ</i>, following e.g. <span class="citation">Siviero et al., 2024</span>. Estimate the parameters of the flow 
            <i>Φ</i>, assuming a linear parametric form via regression. Estimate the transition <i>Q</i>, e.g., considering a discrete set 
            <i>Θ</i>.
        </li>
        <li>
            <strong>Optimal Control:</strong> Develop control strategies for selecting impulse actions 
            \( a \in \mathcal{A}\) to optimize a given cost function, relating the problem to Markov Decision Processes (MDPs).
        </li>
        <li>
            <strong>Uncertainty Quantification:</strong> Quantify uncertainty in the estimated parameters and assess its impact on the system's evolution.
        </li>
        <li>
            <strong>System Analysis:</strong> Analyze the behavior of the extended PD-HMDP under various control strategies, with applications to systems such as agroecosystems or medicine.
        </li>
        <li>
            <strong>Reinforcement Learning strategy:</strong> Design a reinforcement learning strategy, to interact with the system and minimiza cost while learning the different parameters.
        </li>
    </ul>
</div>


<div class="section">
    <h2>Example: Pest Infestation Application: Illustrative Example</h2>
    <p>
        This example models the dynamics of an agroecosystem using a state-space approach. 
        The system is represented by four key state variables, each normalized to lie within the range [0, 1]: 
        <strong>growth</strong> (\(x_1\)), <strong>growth nutrients</strong> (\(x_2\)), 
        <strong>health nutrients</strong> (\(x_3\)), and <strong>pest infestation</strong> (\(x_4\)).
    </p>
    <p>
        Intuitively, the model captures the following interactions:
        <ul>
            <li>
                Plant growth (\(x_1\)) benefits from growth nutrients (\(x_2\)) but is hindered by pest infestation (\(x_4\)).
            </li>
            <li>
                Growth nutrients (\(x_2\)) are depleted as plants grow, reflecting their consumption in supporting plant development.
            </li>
            <li>
                Health nutrients (\(x_3\)) are also consumed during plant growth. A reduction in health nutrients makes plants more vulnerable to pests.
            </li>
            <li>
                Pest infestation (\(x_4\)) increases when health nutrients (\(x_3\)) are low, as plants become less resistant to pest attacks.
            </li>
        </ul>
        Together, these dynamics highlight the feedback loops between plant growth, nutrient levels, and pest infestation, illustrating the challenges in maintaining a healthy agroecosystem.
    </p>
    <p>
        The free dynamics of the system, in the absence of external interventions (e.g., fertilizers or pesticides), can be mathematically defined as follows:
    </p>
    <div class="equations">
        <p>\[
        F(X) = \begin{bmatrix}
        a x_2 - e x_4 \\
        -b x_1 \\
        -c x_1 \\
        d(1 - x_3)
        \end{bmatrix}
        \]</p>
        <ul>
            <li>\(F_1(X) = a x_2 - e x_4\): Growth depends on nutrients for growth (\(x_2\)) and is reduced by pest damage (\(x_4\)).</li>
            <li>\(F_2(X) = -b x_1\): Growth nutrients (\(x_2\)) are depleted proportionally to plant growth (\(x_1\)).</li>
            <li>\(F_3(X) = -c x_1\): Health nutrients (\(x_3\)) are also consumed as plants grow (\(x_1\)).</li>
            <li>\(F_4(X) = d(1 - x_3)\): Pest infestation (\(x_4\)) increases when health nutrients (\(x_3\)) are low.</li>
        </ul>
    </div>
    <p>
        Here, \(a, b, c, d, e\) are constants that define the specific rates of interaction between the variables. This model provides a foundation for simulating the agroecosystem's evolution and exploring strategies to optimize growth while managing nutrient levels and controlling pests.
    </p>
	<p>
        To model the stochastic nature of pest infestations, we incorporate a <strong>Hawkes process</strong> into the system. 
        Specifically, the infestation component (\(x_4\)) of the state \(X_t\) is influenced by the intensity function \(\lambda(x, t)\), 
        which governs the occurrence of pest-related events over time.
    </p>
    <p>
        The intensity function \(\lambda(x, t)\) is defined as:
        <ul>
            <li>For \(i = 1, 2, 3\): \(\lambda_i(x, t) = 0\), as no events are associated with the other state components.</li>
            <li>
                For \(i = 4\): 
                \[
                \lambda_4(x, t) = \mu_4(x - X_t) + \int_{-\infty}^t \phi_4(t - s) dN_s,
                \]
                where:
                <ul>
                    <li>\(\mu_4(x - X_t)\): A baseline intensity determined by the current state \(X_t\), reflecting environmental and agroecosystem factors.</li>
                    <li>\(\phi_4(t - s)\): A self-excitation kernel accounting for the influence of past infestations on future events, with \(\phi_4 = 0\) or a small positive value for sparsity.</li>
                </ul>
            </li>
        </ul>
    </p>
    <p>
        When a pest infestation event occurs, the state \(X_t\) is updated with a small increase (\(\Delta\)) in the infestation component (\(x_4\)), 
        reflecting the immediate impact of the event on the system.
    </p>
    <p>
        This extended model captures the interplay between deterministic system dynamics and stochastic pest infestations, 
        providing a framework for simulating and analyzing scenarios where pest occurrences depend on system conditions and past events.
    </p>
</div>



<div class="bibliography">
    <h3>Bibliography</h3>
    <ul>
        <li><span class="citation-tag">Cleynen et al., 2024</span> Cleynen, A., de Saporta, B., Rossini, O., and Sabbadin, R. (2024). Contrôle dynamique stochastique: une approche à base de modèles semi-markov. In <i>10èmes Rencontres des Jeunes Statistien.ne.s</i>.</li>
        <li><span class="citation-tag">Davis, 1984</span> Davis, M. H. (1984). Piecewise-deterministic markov processes: A general class of non-diffusion stochastic models. <i>Journal of the Royal Statistical Society: Series B (Methodological)</i>, 46(3):353–376.</li>
        <li><span class="citation-tag">De Saporta et al., 2016</span> De Saporta, B., Dufour, F., and Zhang, H. (2016). Numerical methods for simulation and optimization of piecewise deterministic Markov processes: application to reliability. <i>John Wiley & Sons</i>.</li>
        <li><span class="citation-tag">Hawkes, 2018</span> Hawkes, A. G. (2018). Hawkes processes and their applications to finance: a review. <i>Quantitative Finance</i>, 18(2):193–198.</li>
        <li><span class="citation-tag">Puterman, 2014</span> Puterman, M. L. (2014). Markov decision processes: discrete stochastic dynamic programming. <i>John Wiley & Sons</i>.</li>
        <li><span class="citation-tag">Siviero et al., 2024</span> Siviero, E., Staerman, G., Clémençon, S., and Moreau, T. (2024). Flexible parametric inference for space-time hawkes processes. <i>arXiv e-prints</i>, pages arXiv–2406.</li>
        <li><span class="citation-tag">Sutton, 2018</span> Sutton, R. S. (2018). Reinforcement learning: An introduction. <i>A Bradford Book</i>.</li>

    </ul>
</div>


    <!-- Host Institution Section -->
    <div class="section">
        <h3>Host Institution and Supervision</h3>
        <p>The proejct will be hosted at <strong>Centre Inria de l'Université de Lille</strong>, in the Scool team. Scool (Sequential COntinual and Online Learning) focuses on the study of sequential decision-making under uncertainty.</p>
    </div>

    <!-- Footer -->
    <div class="footer">
        <p><a href="mailto:odalric.maillard@inria.fr">Odalric-Ambrym Maillard</a> | <a href="https://www.inria.fr/fr/centre-inria-de-luniversite-de-lille">Inria Lille</a> | <a href="https://team.inria.fr/scool">Scool Team</a> | <a href="https://team.inria.fr/scool/projects">Scool Projects</a></p>
    </div>

</body>
</html>
